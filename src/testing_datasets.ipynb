{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "testing_datasets2.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "GdtYxW7yJZOn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "6d58229f-1424-4ba4-8991-053d56a67e02",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528775963016,
          "user_tz": 180,
          "elapsed": 1846,
          "user": {
            "displayName": "√çtalo Rodrigo",
            "photoUrl": "//lh5.googleusercontent.com/-R_UczsCXXPo/AAAAAAAAAAI/AAAAAAAAAKY/BnvFT9di_gw/s50-c-k-no/photo.jpg",
            "userId": "117142941830902228973"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "arrays.npy\textract_dbn.py\t      modified_dbn.py  svm_test.py\r\n",
            "belief.py\textract_knowledge.py  modified_rbm.py  test_datasets.py\r\n",
            "datalab\t\tinference.py\t      __pycache__      utils.py\r\n",
            "dbn_extract.py\tinsert_knowledge.py   rbm.py\t       yale_dataset\r\n",
            "dbn.py\t\tMNIST_data\t      rule.py\t       yale_dataset.zip\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aGEtYyLvJeoV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UmFX1_BOJsj9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default() \n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LUGtF-0WJvVk",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "uploaded = drive.CreateFile({'parents':[{u'id': \"1HnaZE4RY-8iJkPjwfXwd_kTBjewKvDZs\"}]})\n",
        "uploaded.SetContentFile('arrays.npy')\n",
        "uploaded.Upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6PNUacN5Jyr3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "import extract_knowledge\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from rbm import RBM\n",
        "from utils import tile_raster_images\n",
        "from inference import quantitativeInference"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_wkSfNFDJ04U",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def test_mnist(with_rules=False, one_hot=False, hidden_units=500, n_test=1):\n",
        "    mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=one_hot)\n",
        "    trX, trY, teX, teY = mnist.train.images, mnist.train.labels, mnist.test.images,\\\n",
        "        mnist.test.labels\n",
        "\n",
        "    outputs = []\n",
        "    how_many = 10000\n",
        "    num_classes = 10\n",
        "    accs = []\n",
        "    wr_str = str(with_rules)\n",
        "    hu_str = str(hidden_units)\n",
        "    filename = \"mnist_\" + wr_str + \"_\" + hu_str + \".npy\"\n",
        "\n",
        "    for t in range(n_test):\n",
        "        print(\"\\n--------- TEST {} WITH{} RULES---------\\n\".format(t, \"\" if with_rules==True else \"OUT\"))\n",
        "        rbm = RBM(trX.shape[1], hidden_units)\n",
        "        rbm.train(trX, debug=False)\n",
        "        print(\"!!! RBM trained !!!\")\n",
        "\n",
        "        if with_rules:\n",
        "            rules_rbm = extract_knowledge.rbm_extract(rbm.w)\n",
        "            print(\"Calculating beliefs...\")\n",
        "            new_trX = [quantitativeInference([rules_rbm], x) for x in trX]\n",
        "            new_teX = [quantitativeInference([rules_rbm], x) for x in teX]\n",
        "        else:\n",
        "            input_ = tf.placeholder(\"float\", [None, rbm._input_size])\n",
        "            w_ = tf.placeholder(\"float\", [rbm._input_size, rbm._output_size])\n",
        "            hb_ = tf.placeholder(\"float\", [rbm._output_size])\n",
        "            with tf.Session() as sess:\n",
        "                new_trX = sess.run(rbm.foward_pass(input_, w_, hb_), feed_dict={\n",
        "                    input_: trX, w_: rbm.w, hb_: rbm.hb})\n",
        "                new_teX = sess.run(rbm.foward_pass(input_, w_, hb_), feed_dict={\n",
        "                    input_: teX, w_: rbm.w, hb_: rbm.hb})\n",
        "\n",
        "        svm_inf = SVC()\n",
        "        print(\"Fitting...\")\n",
        "        svm_inf.fit(new_trX, trY)\n",
        "        print(\"Inferring...\")\n",
        "        pred = svm_inf.predict(new_teX)\n",
        "        acc = (np.sum(pred == teY) / teY.shape[0]) * 100\n",
        "        print(\"Accuracy: {}\".format(acc))\n",
        "        accs.append(acc)\n",
        "\n",
        "        # Saving accuracy values\n",
        "        accs_np = np.asarray(accs)\n",
        "        np.save(filename, accs_np)\n",
        "        \n",
        "        # Saving on google drive\n",
        "        auth.authenticate_user()\n",
        "        gauth = GoogleAuth()\n",
        "        gauth.credentials = GoogleCredentials.get_application_default() \n",
        "        drive = GoogleDrive(gauth)\n",
        "        \n",
        "        uploaded = drive.CreateFile({'parents':[{u'id': \"1HnaZE4RY-8iJkPjwfXwd_kTBjewKvDZs\"}]})\n",
        "        uploaded.SetContentFile(filename)\n",
        "        uploaded.Upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WSAWt_fcJ4ks",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def test_yale(with_rules=False, hidden_units=500, n_test=1):\n",
        "    dataset = []\n",
        "    labels = []\n",
        "    accs = []\n",
        "    wr_str = str(with_rules)\n",
        "    hu_str = str(hidden_units)\n",
        "    filename = \"yale_\" + wr_str + \"_\" + hu_str + \".npy\"\n",
        "\n",
        "    # Preparing dataset\n",
        "    for i in range(1, 16):\n",
        "        filelist = glob.glob('./yale_dataset/subject'+str(i).zfill(2)+\"*\")\n",
        "        for filename in filelist:\n",
        "            img = Image.open(filename).convert('L')\n",
        "            img = img.resize((132, 132))\n",
        "            img = np.array(img, dtype=np.float32)\n",
        "            img = np.reshape(img, [img.shape[0]*img.shape[1]])\n",
        "            img = img / 255.\n",
        "            dataset.append(img)\n",
        "            labels.append(float(i))\n",
        "\n",
        "    dataset = np.asarray(dataset)\n",
        "    labels = np.asarray(labels)\n",
        "\n",
        "    for t in range(n_test):\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            dataset, labels, test_size=31, random_state=42, stratify=labels)\n",
        "\n",
        "        print(\"\\n--------- TEST {} WITH{} RULES---------\\n\".format(t, \"\" if with_rules==True else \"OUT\"))\n",
        "        rbm = RBM(X_train.shape[1], with_rules)\n",
        "        rbm.train(dataset, debug=True, epochs=500, batchsize=11, learning_rate=0.1)\n",
        "        print(\"!!! RBM trained !!!\")\n",
        "\n",
        "        if with_rules:\n",
        "            rules_rbm = extract_knowledge.rbm_extract(rbm.w)\n",
        "            print(\"Calculating beliefs...\")\n",
        "            new_trX = [quantitativeInference([rules_rbm], x) for x in X_train]\n",
        "            new_teX = [quantitativeInference([rules_rbm], x) for x in X_test]\n",
        "        else:\n",
        "            input_ = tf.placeholder(\"float\", [None, rbm._input_size])\n",
        "            w_ = tf.placeholder(\"float\", [rbm._input_size, rbm._output_size])\n",
        "            hb_ = tf.placeholder(\"float\", [rbm._output_size])\n",
        "            with tf.Session() as sess:\n",
        "                new_trX = sess.run(rbm.foward_pass(input_, w_, hb_), feed_dict={\n",
        "                                    input_: X_train, w_: rbm.w, hb_: rbm.hb} )\n",
        "                new_teX = sess.run(rbm.foward_pass(input_, w_, hb_), feed_dict={\n",
        "                                    input_: X_test, w_: rbm.w, hb_: rbm.hb} )\n",
        "\n",
        "        svm_inf = SVC()\n",
        "        print(\"Fitting...\")\n",
        "        svm_inf.fit(new_trX, y_train)\n",
        "        print(\"Inferring...\")\n",
        "        pred = svm_inf.predict(new_teX)\n",
        "        acc = (np.sum(pred == y_test) / y_test.shape[0]) * 100\n",
        "        print(\"Accuracy: {}\".format(acc))\n",
        "        accs.append(acc)\n",
        "\n",
        "        # Saving accuracy values\n",
        "        accs_np = np.asarray(accs)\n",
        "        np.save(filename, accs_np)\n",
        "        \n",
        "        # Saving on google drive\n",
        "        auth.authenticate_user()\n",
        "        gauth = GoogleAuth()\n",
        "        gauth.credentials = GoogleCredentials.get_application_default() \n",
        "        drive = GoogleDrive(gauth)\n",
        "        \n",
        "        uploaded = drive.CreateFile({'parents':[{u'id': \"1HnaZE4RY-8iJkPjwfXwd_kTBjewKvDZs\"}]})\n",
        "        uploaded.SetContentFile(filename)\n",
        "        uploaded.Upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3utwVxzjJ7F7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "2dc00add-8112-491f-c8f7-55fdf4b63246"
      },
      "cell_type": "code",
      "source": [
        "# Testing mnist\n",
        "test_mnist(with_rules=False, hidden_units=500, n_test=10)\n",
        "test_mnist(with_rules=False, hidden_units=1000, n_test=10)\n",
        "test_mnist(with_rules=True, hidden_units=500, n_test=10)\n",
        "test_mnist(with_rules=True, hidden_units=1000, n_test=10)\n",
        "\n",
        "# # Testing yale\n",
        "test_yale(with_rules=False, hidden_units=500, n_test=10)\n",
        "test_yale(with_rules=False, hidden_units=1000, n_test=10)\n",
        "test_yale(with_rules=True, hidden_units=500, n_test=10)\n",
        "test_yale(with_rules=True, hidden_units=1000, n_test=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-6-6fd48b594294>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "\n",
            "--------- TEST 0 WITHOUT RULES---------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ow_QuL2DKAjm",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}